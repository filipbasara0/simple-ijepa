{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d05ceca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from simple_ijepa.model import VisionTransformer\n",
    "from simple_ijepa.utils import inference_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea87b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7dccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 96\n",
    "transform = inference_transforms(img_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "train_ds = torchvision.datasets.STL10(\"../data/\",\n",
    "                                  split='train',\n",
    "                                  transform=transform,\n",
    "                                  download=True)\n",
    "val_ds = torchvision.datasets.STL10(\"../data\",\n",
    "                                  split='test',\n",
    "                                  transform=transform,\n",
    "                                  download=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=128,\n",
    "                          num_workers=4)\n",
    "val_loader = DataLoader(val_ds,\n",
    "                       batch_size=128,\n",
    "                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a900a33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a402d632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../models/encoder_best.pth\")\n",
    "\n",
    "dim = 512\n",
    "model = VisionTransformer(image_size=96, patch_size=8, dim=dim, depth=6, heads=6, mlp_dim=dim * 2)\n",
    "\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf731627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def get_embs_labels(dl):\n",
    "    embs, labels = [], []\n",
    "    for images, targets in tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            out = model(images)\n",
    "            features = out.cpu().detach()\n",
    "            features = features.mean(dim = 1)\n",
    "            \n",
    "            embs.extend(features.tolist())\n",
    "            labels.extend(targets.cpu().detach().tolist())\n",
    "\n",
    "    return np.array(embs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4788ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 14.12it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 13.58it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings, labels = get_embs_labels(train_loader)\n",
    "embeddings_val, labels_val = get_embs_labels(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e49f36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def eval():\n",
    "    X_train, X_test = embeddings, embeddings_val\n",
    "    y_train, y_test = labels, labels_val\n",
    "\n",
    "    print(\"train\", X_train.shape[0], len(y_train))\n",
    "    print(\"test\", X_test.shape[0], len(y_test))\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=100)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Confusion matrix: \\n\", conf_matrix)\n",
    "    print(\"Classification report: \\n\", class_report)\n",
    "    \n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    class_report = classification_report(y_train, y_pred_train)\n",
    "    print(\"Classification report train: \\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d0ae774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 5000 5000\n",
      "test 8000 8000\n",
      "Accuracy:  0.77075\n",
      "Confusion matrix: \n",
      " [[703  14  12   3   3   1   4   2  39  19]\n",
      " [ 23 619   1  53  17  29   8  44   5   1]\n",
      " [ 23   4 694   3   1   1   3   1  10  60]\n",
      " [  0  40   1 509  66  88  16  76   3   1]\n",
      " [  1  28   3  53 590  52  49  20   0   4]\n",
      " [  1  28   2  95  53 445  83  88   2   3]\n",
      " [  1   9   1  13  28  86 631  22   1   8]\n",
      " [  2  41   1  47  32  72  14 588   1   2]\n",
      " [ 31   2   3   2   1   0   1   0 728  32]\n",
      " [ 27   2  40   3   1   1   4   4  59 659]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       800\n",
      "           1       0.79      0.77      0.78       800\n",
      "           2       0.92      0.87      0.89       800\n",
      "           3       0.65      0.64      0.64       800\n",
      "           4       0.74      0.74      0.74       800\n",
      "           5       0.57      0.56      0.57       800\n",
      "           6       0.78      0.79      0.78       800\n",
      "           7       0.70      0.73      0.71       800\n",
      "           8       0.86      0.91      0.88       800\n",
      "           9       0.84      0.82      0.83       800\n",
      "\n",
      "    accuracy                           0.77      8000\n",
      "   macro avg       0.77      0.77      0.77      8000\n",
      "weighted avg       0.77      0.77      0.77      8000\n",
      "\n",
      "Classification report train: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       500\n",
      "           1       0.88      0.85      0.87       500\n",
      "           2       0.97      0.96      0.96       500\n",
      "           3       0.78      0.74      0.76       500\n",
      "           4       0.86      0.86      0.86       500\n",
      "           5       0.76      0.74      0.75       500\n",
      "           6       0.82      0.87      0.84       500\n",
      "           7       0.81      0.84      0.83       500\n",
      "           8       0.95      0.95      0.95       500\n",
      "           9       0.93      0.93      0.93       500\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wavelet/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d18dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
